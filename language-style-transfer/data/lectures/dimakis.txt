So we finished 6:45 right? 6:15. Yeah, thats right. That's what we're going to do on Monday. We're going to go till we pass out or we're all done, alright? So Monday December 11th, you have to present and be there. We were aiming for something like 10 minutes, but I want to sit down and see how many teams we have and try to keep it reasonable for everyone. We'll bring pizza, and hopefully survive. It should be fun. And you know we'll hopefully survive. I guess if we're 60 people roughly, over four, is fifteen times ten. two and a half. Eight days? It's a little long. So we're aiming for something like that, like ten minutes something. But there's also overhead in switching, so we're aiming to maybe put everything in one laptop. We'll try to put everything in one laptop so we don't have those delays. Of course. 

Alright. Good. So let's talk today. Just a few words, so projects. Please start seriously thinking about projects. Hopefully I have asked some of graduate students and TAs and myself are helping on different projects. If you, don't be afraid to go into a more fancy direction like the one I'm going to talk about today. Which is pretty awesome. I don't know how you can use it in your project, but you can be quite flexible. You have a lot of time, and that's the good thing. I know most of you will do 90 percent of your project in the last three days, and I hope not. But that's what typically happens. So.

Alright. Do we all know what is transfered learning? Do you know what that is? that is a very useful thing. So. Let's briefly talk about that because you may use it for your project. Transfered learning is, say you want to do some image processing task. Let's say recognizing different types of fruit or something. And you don't have enough training set to build your fruit classifier from a million labeled fruit. It's easy to find a million images, but it's not easy to find a million labeled images. Okay? So. What you do is you download a pretrained neural network that has been trained on a bigger class of problems, like ImageNet. Which is a thousand label neuralnet you can download trained from Google. Then you kill the last layer. So i'm just showing this here in the slide. I'll just show you this idea quickly and then we'll move to generators. So people have trained have trained this massive network. So inceptionv3 is a network that has been trained on images. 1 terabyte dataset of images. Which has a thousand different classes. So you can download these weights and here it has and uses a thousand different labels and it's usually correct. For example this is a cat. Then what you do is you okay so, good, so what you do is take the last slice it here. And you look at this and look at these wires at somepoint here. These wires are very good features and now lets say you want to classify you fruit classifer with only 100 labeled fruit. You're just going to make a logistic regression and make a classifier but instead of looking at pixels you're going to use these things as features. So that's the idea of transfered learning. And you can do this for example, word2vec, which takes words. Did we talk about word2vec? So you can download word2vec and take a vector. And it will have a conceptual distances. So you can use that as a feature, is you have a text now. If you have a text, you can word2vec every word and now you have some sort of embedding of text as a bunch of points in conceptual space. And you will think that text about history would be some point history would be some point here and that text about sport would be somewhere else. So you can use pre trained things to do your tasks which allows you to integrate more knowledge. So it's extremely useful for the types of projects you guys want to do. Because you're not Google and you don't have millions of data that you can use. 

Alright so. That’s the. What i’m saying these are excellent image features and you can train. There’s a google tutorial for tensorflow that can do just that, and you can trivially play with it. 

Now let’s talk about generators. So this lecture is about generative models. Ganns and VAEs. I think I have a. I don’t have a clicker. Too bad. Okay so. Generative models are trying to solve the following problem. We want to discriminators takes pixels to tell if it’s an image of cat or dog. And here we’re going to think of probability distribution that are extremely complication. Like the image the pixels of an image of a face. Okay? So I want to think for a second. Think of a vector of an image, alright? So you have an image like this alright? So it's 64 pixels by 64 pixels and it’s by 3 because it's RGB. So it's 13,000 numbers so you think you can stack these 13 thousand numbers in a big vector here and blah blah blah. 13 thousand numbers. Now. You can think of the space of 13 thousand dimensional vectors, like you can think of 3 dimensional space, you can think of 13 thousand space. So it’s some space here. You randomly think of a point here. It’s going to look like some bunch of random noise. Okay? So what i’m trying to communicate is that you can think about the set of images that human would call human faces, and you can think that this thing creates some sort of weird set here. This set is extremely complicated. Right? But if we had a way, a machine, to somehow randomly pick a point from this set. We would be getting a random human looking face here, right? So that’s what we're trying to do. We’re trying to think of a probability distribution and we want to learn a extremely complicated distribution on theis space like the images corresponding to faces or images corresponding to bedrooms or images corresponding to cats. Or another corresponding to natural images. Which would be a bigger set that would include faces, right? Remarkably, we can sort of do that today, where last year we could not do that. There has been remarkable progress in solving this problem in the last two years, these are called generative models. I would like to push a button and sample randomly from this manifold and think of that as sampling a random face out of all possible faces in the universe. This is unsupervised problem, because there's no labels in this problem. The only input given to us is a bunch of faces that we’re going to train. You can download a data set called celeb a that have been nicely cropped to 64 by 64. So this is going to be our dataset and we want to train a neural network that can sample from this crazy distribution. We’re going to talk about two ways to do that. Were going to talk about maximizing the likelihood of the data. This is the first thing i want you to keep in mind. My first goal is the explain what the hell that means. And the second problem is instead of standard training, there’s a new idea that has only existed for three or four years. And we’re going to talk about both of these ideas and train neural networks. What is standard training? Maximum likelihood training. So we're going to talk about a silly neural network here. That takes as an input two random numbers and so we multiply. So in little bit we’re going tot take a bunch of random numbers and produce faces from them. So maybe, should I be showing you the cool stuff first? So you want the cool stuff first. Alright, fine. Let me see if I have the cool stuff. This is the actual understanding, but, perhaps if I show you cool stuff you will be more motivated to understand. Let’s see here. Okay. 

Alright so. These are the kind of things we’ll be doing. We’re going to build a neural network that takes a hundred numbers, this will be a convolutional layer structure. And you going to pass it through a bunch of them, and this is from actual training from my lab. So this is a very small dimensional number, it's a hundred numbers. This vector is 13 thousand numbers, because it's 64 by 64 by 3. And we put some random numbers in we get this. So this sort of looks like a face but not really. And as we keep training this thing, and I’ll talk about how to train it in a second. So it's a starts getting better and gets here and then gets here and you know at some point we stop. This is different from this by the way. Do you see the difference? Okay. Good. So the thing I want to say here is that this is not the real person. This is some dream that this neural network created from the training process we’re going to talk about. So the questions is how from a set of real images from real faces, we’re going to train these matrices so that this thing looks like real people. That’s the problem. And ideally we’re going to start more and more and maybe I’ll show okay so here I have like any resemblance to actual person is coincidental because these are generated faces. And. maybe here I can show you little bit more cool images before we get into the actual math, and we have covered some of the. So I just want to show what these things typically do now. Okay. Error. So this is adversarial training that we'll be getting next so you see initially the faces look like that but then they get better and better and these are pretty good I think and as you continue training. do you see the slight differences between this and this? And you recognize the one, this one is the one. So. This is achieved through adversarial training. 

Now let's talk about how we do standard training and how we do adversarial training. Anyway let's. Pictures have gotten better than this in the last six months. This was state of the art. But let's understand how this stuff works. Alright. At least at a high level. We're going to think of similar situations as before. Before, we had some Z and then some layer, some layer then the output. So I'm going to make a baby version. This is just a baby generative model that you put in two random numbers and get something out. We want to see how we train these weights. Are you seeing ganns? That's not the coolest. Oh it's not nearly as close to the coolest. There's a lot of stuff which I'll show you and point you to incredible. Okay. So. Let's understand a little bit what we want to do here. Oh very good, what is the point of this? Very good. So that's a very good. So we can generate, we can dream of faces, we can dream of anime characters, that sounds like cute to borderline stupid but-but it actually so. I have a paper where I talk about that. I can show how we can use that for things are actually useful. Like for example, imaging medical tomography. Improving resolution of photography. Missing parts of images, when you have conclusion. Maybe that's more convincing for motivation. I'll show you briefly one application that is real, so let's say that you have. Let's say you only see this. you have a camera and it only sees this part of the image. What can you do so we can actually get this? So we're going to see how it's done in this lecture. This is a problem. Now in this example i have here, in tomography, in CAT scans and MRI and all of imaging models. You observe some projections of whatever object you want to see, you want to see inside the brain, yeah? You don't want to open it up, you use a model like MRI or Computational x-ray and then you use a reconstruction algorithm to do it. So here is a state of the art reconstruction algorithm to do tomography, you don't typically don't do tomography on faces you do it on brain images. But I don't have a GANN on brain images, I have one for faces. So. The point is if you can learn the distribution of faces for faces it's not that interesting. But for images for MRI for brains for example. Then you can use this to do sensing. That's incredibly useful. If you can do it for text, I'm going to show that it's infinitely useful. From translation to missing text, to changing style of text to text classification to automatically mining large texts to find the document that is important. There's an incredible number of uses if you can learn this crazy distribution. Anime characters not so much, but there are many many applications. That being said, let's get into the math of how we do it.

So. Alright. I'm going to tell you two methods of training. Maximal likelihood. In our little example.  



