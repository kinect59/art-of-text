{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Run all cells at once, because there are interdependencies between the code in each cell. Also, some cells take a good 30 minutes to run, so keep that in mind.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All But Shakespeare's Works (Remove stuff before Preface/Chapter 1 and Anything after \"End of Project...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A lot of these e-books are inconsistent with each other. For example, Prefaces may begin near the end of the book. As a suggestion, the books that were processed \"improperly\" could be used as test data. There does not seem to be a sure-fire way to write this thing in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mukund\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book will be processed: Dickens Bleak_House.txt\n",
      "This book will be processed: Dickens David_Copperfield.txt\n",
      "This book will be processed: Dickens Dombey_and_Son.txt\n",
      "This book will be processed: Dickens Great_Expectations.txt\n",
      "This book will be processed: Dickens Little_Dorrit.txt\n",
      "This book will be processed: Dickens Nicholas_Nickleby.txt\n",
      "This book will be processed: Dickens Oliver_Twist.txt\n",
      "This book will be processed: Dickens Our_Mutual_Friend.txt\n",
      "This book will be processed: Dickens The_Letters_of_Charles_Dickens.txt\n",
      "This book will be processed: Dickens The_Pickwick_Papers.txt\n",
      "This book will be processed: Tolstoy Anna_Karenina.txt\n",
      "This book will be processed: Tolstoy Kingdom_of_God_is_Within_You.txt\n",
      "This book will be processed: Tolstoy Sevastopol.txt\n",
      "This book will be processed: Tolstoy The_Cossacks.txt\n",
      "This book will be processed: Tolstoy The_Kreutzer_Sonata_and_Other_Stories.txt\n",
      "This book will be processed: Tolstoy The_Resurrection.txt\n",
      "This book will be processed: Tolstoy War_And_Peace.txt\n",
      "This book will be processed: Twain Adventures_of_Huckleberry_Finn.txt\n",
      "This book will be processed: Twain A_Connecticut_Yankee_in_King_Arthur's_Court.txt\n",
      "This book will be processed: Twain Life_on_the_Mississippi.txt\n",
      "This book will be processed: Twain Roughing_It.txt\n",
      "This book will be processed: Twain The_Adventures_Of_Tom_Sawyer.txt\n",
      "This book will be processed: Twain The_Innocents_Abroad.txt\n",
      "This book will be processed: Twain The_Prince_And_The_Pauper.txt\n",
      "This book will be processed: Twain The_Tragedy_of_Pudd'nhead_Wilson.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Get all the Authors to go through:\n",
    "dirList = list()\n",
    "for root, dirs, files in os.walk(\"../RawBooks\", topdown=False):\n",
    "    for name in dirs:\n",
    "        if (name != \".ipynb_checkpoints\"):\n",
    "            dirList.append(name)\n",
    "\n",
    "#Iterate through directory and process the data:\n",
    "for dirs in dirList:\n",
    "    if (dirs != \"Shakespeare\"):\n",
    "        for file in os.listdir(os.fsencode(\"../RawBooks/\" + dirs)):\n",
    "            filename = os.fsdecode(file)\n",
    "            print(\"This book will be processed: \" + dirs + \" \" + str(filename))\n",
    "\n",
    "            #Read in the raw data as a string\n",
    "            rawDataFile = open(\"../RawBooks/\" + dirs + \"/\"+ str(filename), \"r\", encoding=\"utf-8\")\n",
    "            rawData = rawDataFile.read() #type(rawData) == string\n",
    "            \n",
    "            #Now we need to find the first occurence of what we would expect to see\n",
    "            #For a book, look for \"Preface\" or \"Chapter 1\"\n",
    "            if (rawData.find(\"PREFACE\") != -1):\n",
    "                if (rawData.find(\"End of the Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"PREFACE\"):rawData.find(\"End of the Project\")]\n",
    "                elif (rawData.find(\"End of Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"PREFACE\"):rawData.find(\"End of Project\")]\n",
    "                elif (rawData.find(\"END OF THE PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"PREFACE\"):rawData.find(\"END OF THE PROJECT\")]\n",
    "                elif (rawData.find(\"END OF THIS PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"PREFACE\"):rawData.find(\"END OF THIS PROJECT\")]\n",
    "            elif (rawData.find(\"CHAPTER I\") != -1):\n",
    "                if (rawData.find(\"End of the Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER I\"):rawData.find(\"End of the Project\")]\n",
    "                elif (rawData.find(\"End of Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER I\"):rawData.find(\"End of Project\")]\n",
    "                elif (rawData.find(\"END OF THE PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER I\"):rawData.find(\"END OF THE PROJECT\")]\n",
    "                elif (rawData.find(\"END OF THIS PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER I\"):rawData.find(\"END OF THIS PROJECT\")]\n",
    "            elif (rawData.find(\"CHAPTER 1\") != -1):\n",
    "                if (rawData.find(\"End of the Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER 1\"):rawData.find(\"End of the Project\")]\n",
    "                elif (rawData.find(\"End of Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER 1\"):rawData.find(\"End of Project\")]\n",
    "                elif (rawData.find(\"END OF THE PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER 1\"):rawData.find(\"END OF THE PROJECT\")]\n",
    "                elif (rawData.find(\"END OF THIS PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"CHAPTER 1\"):rawData.find(\"END OF THIS PROJECT\")]\n",
    "            elif (rawData.find(\"Chapter 1\") != -1):\n",
    "                if (rawData.find(\"End of the Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter 1\"):rawData.find(\"End of the Project\")]\n",
    "                elif (rawData.find(\"End of Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter 1\"):rawData.find(\"End of Project\")]\n",
    "                elif (rawData.find(\"END OF THE PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter 1\"):rawData.find(\"END OF THE PROJECT\")]\n",
    "                elif (rawData.find(\"END OF THIS PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter 1\"):rawData.find(\"END OF THIS PROJECT\")]\n",
    "            elif (rawData.find(\"Chapter I\") != -1):\n",
    "                if (rawData.find(\"End of the Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter I\"):rawData.find(\"End of the Project\")]\n",
    "                elif (rawData.find(\"End of Project\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter I\"):rawData.find(\"End of Project\")]\n",
    "                elif (rawData.find(\"END OF THE PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter I\"):rawData.find(\"END OF THE PROJECT\")]\n",
    "                elif (rawData.find(\"END OF THIS PROJECT\") != -1):\n",
    "                    processedText = rawData[rawData.find(\"Chapter I\"):rawData.find(\"END OF THIS PROJECT\")]\n",
    "                \n",
    "            finalFile = open(dirs + \"/\" + str(filename), \"w\", encoding=\"utf-8\")\n",
    "            finalFile.write(processedText)\n",
    "            finalFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing to trash data (Remove words like \"Chapter\" and any other relatively useless words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mukund\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book will be processed: Dickens Bleak_House.txt\n",
      "This book will be processed: Dickens David_Copperfield.txt\n",
      "This book will be processed: Dickens Dombey_and_Son.txt\n",
      "This book will be processed: Dickens Great_Expectations.txt\n",
      "This book will be processed: Dickens Little_Dorrit.txt\n",
      "This book will be processed: Dickens Nicholas_Nickleby.txt\n",
      "This book will be processed: Dickens Oliver_Twist.txt\n",
      "This book will be processed: Dickens Our_Mutual_Friend.txt\n",
      "This book will be processed: Dickens The_Letters_of_Charles_Dickens.txt\n",
      "This book will be processed: Dickens The_Pickwick_Papers.txt\n",
      "This book will be processed: Tolstoy Anna_Karenina.txt\n",
      "This book will be processed: Tolstoy Kingdom_of_God_is_Within_You.txt\n",
      "This book will be processed: Tolstoy Sevastopol.txt\n",
      "This book will be processed: Tolstoy The_Cossacks.txt\n",
      "This book will be processed: Tolstoy The_Kreutzer_Sonata_and_Other_Stories.txt\n",
      "This book will be processed: Tolstoy The_Resurrection.txt\n",
      "This book will be processed: Tolstoy War_And_Peace.txt\n",
      "This book will be processed: Twain Adventures_of_Huckleberry_Finn.txt\n",
      "This book will be processed: Twain A_Connecticut_Yankee_in_King_Arthur's_Court.txt\n",
      "This book will be processed: Twain Life_on_the_Mississippi.txt\n",
      "This book will be processed: Twain Roughing_It.txt\n",
      "This book will be processed: Twain The_Adventures_Of_Tom_Sawyer.txt\n",
      "This book will be processed: Twain The_Innocents_Abroad.txt\n",
      "This book will be processed: Twain The_Prince_And_The_Pauper.txt\n",
      "This book will be processed: Twain The_Tragedy_of_Pudd'nhead_Wilson.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Get all the Authors to go through:\n",
    "dirList = list()\n",
    "for root, dirs, files in os.walk(\"../Processed\", topdown=False):\n",
    "    for name in dirs:\n",
    "        if (name != \".ipynb_checkpoints\"):\n",
    "            dirList.append(name)\n",
    "\n",
    "################################Delete all occurrences of this string##################################\n",
    "def axeAllInstances(instance, arrToRemFrom):\n",
    "    indexIntoRawArr = 0 #A way to avoid the dynamically changing size of arrToRemFrom\n",
    "            \n",
    "    while indexIntoRawArr < len(arrToRemFrom): #While we can avoid outOfBounds errors\n",
    "        if (arrToRemFrom[indexIntoRawArr].find(instance) != -1):\n",
    "            arrToRemFrom.remove(arrToRemFrom[indexIntoRawArr])\n",
    "        indexIntoRawArr = indexIntoRawArr + 1\n",
    "\n",
    "    return arrToRemFrom\n",
    "################################End of Function########################################################\n",
    "\n",
    "#Iterate through directory and process the data:\n",
    "for dirs in dirList:\n",
    "    if (dirs != \"Shakespeare\"):\n",
    "        for file in os.listdir(os.fsencode(dirs)):\n",
    "            filename = os.fsdecode(file)\n",
    "            print(\"This book will be processed: \" + dirs + \" \" + str(filename))\n",
    "\n",
    "            #Read in the raw data as a string\n",
    "            rawDataFile = open(\"../Processed/\" + dirs + \"/\"+ str(filename), \"r\", encoding=\"utf-8\")\n",
    "            rawData = rawDataFile.read() #type(rawData) == string\n",
    "            rawDataLines = []\n",
    "            rawDataLines = rawData.split(\"\\n\") #Easier to do this, if we store text as a list\n",
    "            \n",
    "            #Now we need to find every occurence of a useless word (for example: CHAPTER)\n",
    "            #Big hint: Useless words are usually all caps...usually\n",
    "            #Made a function to do this, so we just call that a bunch of times\n",
    "            rawDataLines = axeAllInstances(\"PREFACE\", rawDataLines)\n",
    "            rawDataLines = axeAllInstances(\"CHAPTER\", rawDataLines)\n",
    "            rawDataLines = axeAllInstances(\"Chapter\", rawDataLines)\n",
    "            \n",
    "            #Make a string out of the list:\n",
    "            processedText = '' #Final Result\n",
    "            for i in range(len(rawDataLines)):\n",
    "                if (i < (len(rawDataLines) - 1)): #Append new line chars to all but the last line\n",
    "                    processedText = processedText + rawDataLines[i] + \"\\n\"\n",
    "                else:\n",
    "                    processedText = processedText + rawDataLines[i]\n",
    "            \n",
    "            #Write the processed text to a new file and store the processed file:\n",
    "            finalFile = open(dirs + \"/\" + str(filename), \"w\", encoding=\"utf-8\")\n",
    "            finalFile.write(processedText)\n",
    "            finalFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
